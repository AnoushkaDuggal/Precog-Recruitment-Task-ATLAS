{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hsot3kB8gVAa",
        "outputId": "502f4cb8-c894-483c-ceb9-5e6336fa2213"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "pKcgxcLtghRC",
        "outputId": "6b295245-f7ad-4cc7-d870-fc8fa67626ef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
            "Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.1\n",
            "    Uninstalling scipy-1.16.1:\n",
            "      Successfully uninstalled scipy-1.16.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "a3a4e5611c6f4675bb87c12c38ba2274"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "W42RBI0eUxFE"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from gensim.models import Word2Vec\n",
        "import itertools\n",
        "from collections import Counter\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "countries = [\n",
        "    \"Afghanistan\", \"Albania\", \"Algeria\", \"Andorra\", \"Angola\", \"Antigua and Barbuda\", \"Argentina\", \"Armenia\",\n",
        "    \"Australia\", \"Austria\", \"Azerbaijan\", \"Bahamas\", \"Bahrain\", \"Bangladesh\", \"Barbados\", \"Belarus\", \"Belgium\",\n",
        "    \"Belize\", \"Benin\", \"Bhutan\", \"Bolivia\", \"Bosnia and Herzegovina\", \"Botswana\", \"Brazil\", \"Brunei\", \"Bulgaria\",\n",
        "    \"Burkina Faso\", \"Burundi\", \"Cambodia\", \"Cameroon\", \"Canada\", \"Cape Verde\", \"Central African Republic\", \"Chad\",\n",
        "    \"Chile\", \"China\", \"Colombia\", \"Comoros\", \"Congo\", \"Costa Rica\", \"Côte d'Ivoire\", \"Croatia\", \"Cuba\", \"Cyprus\",\n",
        "    \"Czech Republic\", \"North Korea\", \"Democratic Republic of the Congo\", \"Denmark\", \"Djibouti\", \"Dominica\",\n",
        "    \"Dominican Republic\", \"Ecuador\", \"Egypt\", \"El Salvador\", \"Equatorial Guinea\", \"Eritrea\", \"Estonia\", \"Eswatini\",\n",
        "    \"Ethiopia\", \"Fiji\", \"Finland\", \"France\", \"Gabon\", \"Gambia\", \"Georgia\", \"Germany\", \"Ghana\", \"Greece\", \"Grenada\",\n",
        "    \"Guatemala\", \"Guinea\", \"Guinea-Bissau\", \"Guyana\", \"Haiti\", \"Honduras\", \"Hungary\", \"Iceland\", \"India\",\n",
        "    \"Indonesia\", \"Iran\", \"Iraq\", \"Ireland\", \"Israel\", \"Italy\", \"Jamaica\", \"Japan\", \"Jordan\", \"Kazakhstan\", \"Kenya\",\n",
        "    \"Kiribati\", \"Kuwait\", \"Kyrgyzstan\", \"Laos\", \"Latvia\", \"Lebanon\", \"Lesotho\", \"Liberia\", \"Libya\", \"Liechtenstein\",\n",
        "    \"Lithuania\", \"Luxembourg\", \"Madagascar\", \"Malawi\", \"Malaysia\", \"Maldives\", \"Mali\", \"Malta\", \"Marshall Islands\",\n",
        "    \"Mauritania\", \"Mauritius\", \"Mexico\", \"Micronesia\", \"Monaco\", \"Mongolia\", \"Montenegro\", \"Morocco\", \"Mozambique\",\n",
        "    \"Myanmar\", \"Namibia\", \"Nauru\", \"Nepal\", \"Netherlands\", \"New Zealand\", \"Nicaragua\", \"Niger\", \"Nigeria\",\n",
        "    \"North Macedonia\", \"Norway\", \"Oman\", \"Pakistan\", \"Palau\", \"Panama\", \"Papua New Guinea\", \"Paraguay\", \"Peru\",\n",
        "    \"Philippines\", \"Poland\", \"Portugal\", \"Qatar\", \"South Korea\", \"Moldova\", \"Romania\", \"Russia\", \"Rwanda\",\n",
        "    \"Saint Kitts and Nevis\", \"Saint Lucia\", \"Saint Vincent and the Grenadines\", \"Samoa\", \"San Marino\",\n",
        "    \"São Tomé and Príncipe\", \"Saudi Arabia\", \"Senegal\", \"Serbia\", \"Seychelles\", \"Sierra Leone\", \"Singapore\",\n",
        "    \"Slovakia\", \"Slovenia\", \"Solomon Islands\", \"Somalia\", \"South Africa\", \"South Sudan\", \"Spain\", \"Sri Lanka\",\n",
        "    \"Sudan\", \"Suriname\", \"Sweden\", \"Switzerland\", \"Syria\", \"Tajikistan\", \"Tanzania\", \"Thailand\", \"Timor-Leste\",\n",
        "    \"Togo\", \"Tonga\", \"Trinidad and Tobago\", \"Tunisia\", \"Turkey\", \"Turkmenistan\", \"Tuvalu\", \"Uganda\", \"Ukraine\",\n",
        "    \"United Arab Emirates\", \"United Kingdom\", \"United States\", \"Uruguay\", \"Uzbekistan\", \"Vanuatu\", \"Venezuela\",\n",
        "    \"Vietnam\", \"Yemen\", \"Zambia\", \"Zimbabwe\"\n",
        "]\n",
        "\n",
        "atlas_graph = nx.DiGraph()\n",
        "atlas_graph.add_nodes_from(countries)\n",
        "edges = [\n",
        "    (c1, c2) for c1, c2 in itertools.product(countries, repeat=2)\n",
        "    if c1 != c2 and c1.lower()[-1] == c2.lower()[0]\n",
        "]\n",
        "atlas_graph.add_edges_from(edges)"
      ],
      "metadata": {
        "id": "1ggLGofGe0jq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CountryPopularityScorer:\n",
        "    def __init__(self, country_list):\n",
        "        # Sources: This data is representative of figures from sources like The World Bank (Population, GDP) and cultural influence rankings (e.g., U.S. News Best Countries Report).\n",
        "        self.population_data = {\n",
        "            'China': 1440, 'India': 1380, 'United States': 331, 'Indonesia': 273, 'Pakistan': 225, 'Brazil': 213,\n",
        "            'Nigeria': 211, 'Bangladesh': 165, 'Russia': 146, 'Mexico': 129, 'Japan': 125, 'Germany': 83,\n",
        "            'United Kingdom': 68, 'France': 68, 'Italy': 60, 'South Africa': 59, 'South Korea': 52,\n",
        "            'Colombia': 51, 'Spain': 47, 'Argentina': 45, 'Canada': 38, 'Saudi Arabia': 35, 'Australia': 25\n",
        "        }\n",
        "        self.economic_prominence = {\n",
        "            'United States': 10, 'China': 9, 'Japan': 8, 'Germany': 8, 'India': 7, 'United Kingdom': 7,\n",
        "            'France': 7, 'Italy': 6, 'Brazil': 6, 'Canada': 6, 'Russia': 6, 'South Korea': 6, 'Australia': 5,\n",
        "            'Spain': 5, 'Mexico': 5, 'Indonesia': 5, 'Netherlands': 5, 'Saudi Arabia': 5, 'Turkey': 4,\n",
        "            'Switzerland': 4, 'Argentina': 4, 'Nigeria': 4\n",
        "        }\n",
        "        self.cultural_prominence = {\n",
        "            'United States': 10, 'United Kingdom': 8, 'France': 7, 'Italy': 7, 'Germany': 6, 'Japan': 8,\n",
        "            'Australia': 6, 'Canada': 6, 'Spain': 6, 'China': 7, 'India': 8, 'Brazil': 7, 'Russia': 6,\n",
        "            'Mexico': 6, 'South Korea': 8, 'Egypt': 5, 'Greece': 5, 'Turkey': 5\n",
        "        }\n",
        "        self.all_countries = country_list\n",
        "        self.popularity_scores = self._calculate_popularity_scores()\n",
        "\n",
        "    def _calculate_popularity_scores(self):\n",
        "        scores = {}\n",
        "        max_pop = max(self.population_data.values())\n",
        "\n",
        "        for country in self.all_countries:\n",
        "            pop_score = np.log1p(self.population_data.get(country, 0)) / np.log1p(max_pop)\n",
        "\n",
        "            econ_score = self.economic_prominence.get(country, 1) / 10.0\n",
        "            cult_score = self.cultural_prominence.get(country, 1) / 10.0\n",
        "\n",
        "            combined_score = (pop_score * 0.2) + (econ_score * 0.4) + (cult_score * 0.4)\n",
        "            scores[country] = combined_score\n",
        "\n",
        "        max_score = max(scores.values())\n",
        "        min_score = min(scores.values())\n",
        "        final_scores = {k: (v - min_score) / (max_score - min_score) for k, v in scores.items()}\n",
        "        return final_scores\n",
        "\n",
        "    def get_score(self, country):\n",
        "        return self.popularity_scores.get(country, 0)\n",
        "\n",
        "popularity_scorer = CountryPopularityScorer(countries)"
      ],
      "metadata": {
        "id": "uwklyaaeiXUw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AtlasFeatureEngineer:\n",
        "    def __init__(self, graph, country_list, scorer):\n",
        "        self.graph = graph\n",
        "        self.countries = country_list\n",
        "        self.scorer = scorer\n",
        "\n",
        "    def create_combined_features(self, normalize=True):\n",
        "        letter_features = self._create_letter_features()\n",
        "        structural_features = self._create_structural_features()\n",
        "        linguistic_features = self._create_linguistic_features()\n",
        "        popularity_features = self._create_popularity_features()\n",
        "        combined = np.concatenate([\n",
        "            letter_features, structural_features, linguistic_features, popularity_features\n",
        "        ], axis=1)\n",
        "        if normalize:\n",
        "            scaler = StandardScaler()\n",
        "            combined = scaler.fit_transform(combined)\n",
        "        return combined\n",
        "\n",
        "    def _create_letter_features(self):\n",
        "        all_letters = sorted(list(set(c[0].lower() for c in self.countries) | set(c[-1].lower() for c in self.countries)))\n",
        "        letter_map = {letter: i for i, letter in enumerate(all_letters)}\n",
        "        num_letters = len(all_letters)\n",
        "        features = []\n",
        "        for country in self.countries:\n",
        "            first, last = [0] * num_letters, [0] * num_letters\n",
        "            first[letter_map[country[0].lower()]] = 1\n",
        "            last[letter_map[country[-1].lower()]] = 1\n",
        "            features.append(first + last)\n",
        "        return np.array(features)\n",
        "\n",
        "    def _create_structural_features(self):\n",
        "        pagerank = nx.pagerank(self.graph)\n",
        "        betweenness = nx.betweenness_centrality(self.graph)\n",
        "        features = []\n",
        "        for country in self.countries:\n",
        "            features.append([\n",
        "                self.graph.in_degree(country), self.graph.out_degree(country),\n",
        "                pagerank.get(country, 0), betweenness.get(country, 0)\n",
        "            ])\n",
        "        return np.array(features)\n",
        "\n",
        "    def _create_linguistic_features(self):\n",
        "        vowels = set('aeiou')\n",
        "        features = []\n",
        "        for country in self.countries:\n",
        "            name = country.lower()\n",
        "            features.append([len(name), len(name.replace(' ', '')), sum(1 for char in name if char in vowels)])\n",
        "        return np.array(features)\n",
        "\n",
        "    def _create_popularity_features(self):\n",
        "        return np.array([[self.scorer.get_score(country)] for country in self.countries])\n",
        "\n",
        "feature_engineer = AtlasFeatureEngineer(atlas_graph, countries, popularity_scorer)\n",
        "node_features = feature_engineer.create_combined_features()"
      ],
      "metadata": {
        "id": "GBJG_8WPhJmN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node2VecLinkPredictor:\n",
        "    def __init__(self, graph, dimensions=64, walk_length=20, num_walks=100):\n",
        "        self.graph = graph\n",
        "        self.dimensions = dimensions\n",
        "        self.walk_length = walk_length\n",
        "        self.num_walks = num_walks\n",
        "        self.model = None\n",
        "\n",
        "    def train(self):\n",
        "        walks = self._generate_walks()\n",
        "        self.model = Word2Vec(walks, vector_size=self.dimensions, window=5, min_count=1, sg=1, workers=4)\n",
        "\n",
        "    def get_embeddings(self):\n",
        "        return np.array([self.model.wv[node] for node in self.graph.nodes()])\n",
        "\n",
        "    def _generate_walks(self):\n",
        "        walks = []\n",
        "        for _ in range(self.num_walks):\n",
        "            for node in self.graph.nodes():\n",
        "                walk = [node]\n",
        "                while len(walk) < self.walk_length:\n",
        "                    current = walk[-1]\n",
        "                    neighbors = list(self.graph.successors(current))\n",
        "                    if len(neighbors) > 0:\n",
        "                        walk.append(np.random.choice(neighbors))\n",
        "                    else:\n",
        "                        break\n",
        "                walks.append(walk)\n",
        "        return walks\n",
        "\n",
        "class GNNLinkPredictor(nn.Module):\n",
        "    def __init__(self, num_features, hidden_dim=64, num_layers=2, heads=4, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(GATConv(num_features, hidden_dim, heads=heads, dropout=dropout))\n",
        "        if num_layers > 1:\n",
        "            self.convs.append(GATConv(hidden_dim * heads, hidden_dim, heads=1, concat=False, dropout=dropout))\n",
        "\n",
        "        self.link_predictor = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "        )\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            x = conv(x, edge_index)\n",
        "            if i < len(self.convs) - 1:\n",
        "                x = F.elu(x)\n",
        "                x = F.dropout(x, p=0.6, training=self.training)\n",
        "        return x\n",
        "\n",
        "    def decode(self, z, edge_label_index):\n",
        "        edge_embeddings = torch.cat([z[edge_label_index[0]], z[edge_label_index[1]]], dim=-1)\n",
        "        return self.link_predictor(edge_embeddings).squeeze()"
      ],
      "metadata": {
        "id": "BbIDiZpbhKjD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_tensor = torch.tensor(node_features, dtype=torch.float)\n",
        "edge_index = torch.tensor([[list(atlas_graph.nodes()).index(u), list(atlas_graph.nodes()).index(v)] for u, v in atlas_graph.edges()], dtype=torch.long).t().contiguous()\n",
        "data = Data(x=features_tensor, edge_index=edge_index)\n",
        "transform = RandomLinkSplit(num_val=0.1, num_test=0.1, is_undirected=False, add_negative_train_samples=True)\n",
        "train_data, val_data, test_data = transform(data)\n",
        "\n",
        "# Evaluate Node2Vec\n",
        "print(\"Training and Evaluating Model 1: Node2Vec\")\n",
        "node2vec = Node2VecLinkPredictor(atlas_graph)\n",
        "print(\"Training Node2Vec model\")\n",
        "node2vec.train()\n",
        "print(\"Node2Vec training complete.\")\n",
        "embeddings = node2vec.get_embeddings()\n",
        "\n",
        "train_pos_edges = train_data.edge_label_index[:, train_data.edge_label == 1]\n",
        "train_neg_edges = train_data.edge_label_index[:, train_data.edge_label == 0]\n",
        "pos_train_feat = embeddings[train_pos_edges[0]] * embeddings[train_pos_edges[1]]\n",
        "neg_train_feat = embeddings[train_neg_edges[0]] * embeddings[train_neg_edges[1]]\n",
        "X_train = np.vstack([pos_train_feat, neg_train_feat])\n",
        "y_train = np.hstack([np.ones(pos_train_feat.shape[0]), np.zeros(neg_train_feat.shape[0])])\n",
        "\n",
        "lr = LogisticRegression(solver='liblinear', max_iter=1000)\n",
        "print(\"Training a classifier on Node2Vec embeddings\")\n",
        "lr.fit(X_train, y_train)\n",
        "print(\"Classifier training complete.\")\n",
        "\n",
        "test_pos_edges = test_data.edge_label_index[:, test_data.edge_label == 1]\n",
        "test_neg_edges = test_data.edge_label_index[:, test_data.edge_label == 0]\n",
        "pos_test_feat = embeddings[test_pos_edges[0]] * embeddings[test_pos_edges[1]]\n",
        "neg_test_feat = embeddings[test_neg_edges[0]] * embeddings[test_neg_edges[1]]\n",
        "X_test = np.vstack([pos_test_feat, neg_test_feat])\n",
        "y_test = np.hstack([np.ones(pos_test_feat.shape[0]), np.zeros(neg_test_feat.shape[0])])\n",
        "\n",
        "test_probs = lr.predict_proba(X_test)[:, 1]\n",
        "n2v_auc = roc_auc_score(y_test, test_probs)\n",
        "n2v_ap = average_precision_score(y_test, test_probs)\n",
        "\n",
        "# Evaluate GNN\n",
        "print(\"Training and Evaluating Model 2: GNN (Graph Attention Network)\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GNNLinkPredictor(data.num_features).to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(train_data.x.to(device), train_data.edge_index.to(device))\n",
        "    out = model.decode(z, train_data.edge_label_index.to(device))\n",
        "    loss = criterion(out, train_data.edge_label.to(device).float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    z = model.encode(data.x.to(device), data.edge_index.to(device))\n",
        "    out = model.decode(z, data.edge_label_index.to(device))\n",
        "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
        "\n",
        "for epoch in range(1, 201):\n",
        "    loss = train()\n",
        "    if epoch % 20 == 0:\n",
        "        val_auc = test(val_data)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val AUC: {val_auc:.4f}')\n",
        "\n",
        "gnn_auc = test(test_data)\n",
        "z_gnn = model.encode(test_data.x.to(device), test_data.edge_index.to(device))\n",
        "out_gnn = model.decode(z_gnn, test_data.edge_label_index.to(device))\n",
        "gnn_ap = average_precision_score(test_data.edge_label.cpu().numpy(), torch.sigmoid(out_gnn).cpu().detach().numpy())\n",
        "\n",
        "#Comparison\n",
        "print(\"FINAL MODEL PERFORMANCE COMPARISON\")\n",
        "results_df = pd.DataFrame([\n",
        "    {'Model': 'Node2Vec', 'Test AUC': n2v_auc, 'Test AP': n2v_ap},\n",
        "    {'Model': 'GNN (GAT)', 'Test AUC': gnn_auc, 'Test AP': gnn_ap}\n",
        "])\n",
        "print(results_df.to_string(index=False, float_format='%.4f'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OaTJ62ihPwU",
        "outputId": "ecd60920-40e2-45ac-f8bd-4aef94239218"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and Evaluating Model 1: Node2Vec\n",
            "Training Node2Vec model\n",
            "Node2Vec training complete.\n",
            "Training a classifier on Node2Vec embeddings\n",
            "Classifier training complete.\n",
            "Training and Evaluating Model 2: GNN (Graph Attention Network)\n",
            "Epoch: 020, Loss: 0.5090, Val AUC: 0.8303\n",
            "Epoch: 040, Loss: 0.4922, Val AUC: 0.8609\n",
            "Epoch: 060, Loss: 0.4501, Val AUC: 0.8935\n",
            "Epoch: 080, Loss: 0.3907, Val AUC: 0.9064\n",
            "Epoch: 100, Loss: 0.3765, Val AUC: 0.9232\n",
            "Epoch: 120, Loss: 0.3075, Val AUC: 0.9438\n",
            "Epoch: 140, Loss: 0.3051, Val AUC: 0.9459\n",
            "Epoch: 160, Loss: 0.2865, Val AUC: 0.9470\n",
            "Epoch: 180, Loss: 0.2959, Val AUC: 0.9472\n",
            "Epoch: 200, Loss: 0.2689, Val AUC: 0.9496\n",
            "FINAL MODEL PERFORMANCE COMPARISON\n",
            "    Model  Test AUC  Test AP\n",
            " Node2Vec    0.8337   0.8162\n",
            "GNN (GAT)    0.9618   0.9628\n"
          ]
        }
      ]
    }
  ]
}